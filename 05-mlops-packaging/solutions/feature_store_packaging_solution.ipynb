{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95da5589",
   "metadata": {},
   "source": [
    "## Section 1: Environment Setup\n",
    "\n",
    "This section establishes the SageMaker environment configuration. We import necessary libraries and configure the session with appropriate IAM roles and S3 bucket settings.\n",
    "\n",
    "The configuration is compatible with multiple environments: SageMaker Studio, SageMaker Notebook Instances, and local development setups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d2d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Configuration SageMaker Universelle\n",
    "# Compatible avec Studio, Notebook Instances et Local\n",
    "# ============================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ajouter le chemin du projet\n",
    "project_root = os.path.abspath('../..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Imports SageMaker\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.feature_store.feature_definition import (\n",
    "    FeatureDefinition,\n",
    "    FeatureTypeEnum\n",
    ")\n",
    "\n",
    "# Imports data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "# Configuration\n",
    "try:\n",
    "    from utils.sagemaker_config import get_sagemaker_config\n",
    "    config = get_sagemaker_config(s3_prefix='lab5-feature-store')\n",
    "    role = config['role']\n",
    "    session = config['session']\n",
    "    bucket = config['bucket']\n",
    "    region = config['region']\n",
    "except ImportError:\n",
    "    print(\"Using fallback configuration method\")\n",
    "    role = get_execution_role()\n",
    "    session = sagemaker.Session()\n",
    "    bucket = session.default_bucket()\n",
    "    region = session.boto_region_name\n",
    "\n",
    "print(\"Configuration complete\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"S3 Bucket: s3://{bucket}\")\n",
    "print(f\"IAM Role: {role[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3189546",
   "metadata": {},
   "source": [
    "## Section 2: Synthetic Data Generation\n",
    "\n",
    "In this section, we generate synthetic customer transaction features for a fraud detection use case. The dataset simulates realistic patterns found in financial transactions.\n",
    "\n",
    "### Feature Schema\n",
    "\n",
    "The following features will be created to represent customer transaction behavior:\n",
    "\n",
    "| Feature Name | Data Type | Description |\n",
    "|-------------|-----------|-------------|\n",
    "| customer_id | String | Unique customer identifier (primary key) |\n",
    "| event_time | String | Event timestamp in ISO 8601 format |\n",
    "| transaction_count_30d | Float | Number of transactions in last 30 days |\n",
    "| total_amount_30d | Float | Total transaction amount in last 30 days |\n",
    "| avg_transaction_amount | Float | Average transaction amount |\n",
    "| merchant_category_mode | String | Most frequent merchant category |\n",
    "| distance_from_home_avg | Float | Average distance from home address (km) |\n",
    "| is_high_risk | Integer | Binary risk indicator (0=normal, 1=high risk) |\n",
    "\n",
    "The synthetic data generation incorporates realistic statistical distributions to mimic actual transaction patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Génération de Données Synthétiques\n",
    "# ============================================================\n",
    "\n",
    "def generate_customer_features(n_customers=1000):\n",
    "    \"\"\"\n",
    "    Génère des features synthétiques pour des clients\n",
    "    \n",
    "    Args:\n",
    "        n_customers: Nombre de clients à générer\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame avec features clients\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Générer customer IDs\n",
    "    customer_ids = [f\"CUST_{str(i).zfill(6)}\" for i in range(1, n_customers + 1)]\n",
    "    \n",
    "    # Timestamp actuel\n",
    "    current_time = datetime.utcnow()\n",
    "    \n",
    "    # Générer features\n",
    "    data = {\n",
    "        'customer_id': customer_ids,\n",
    "        'event_time': [\n",
    "            (current_time - timedelta(minutes=np.random.randint(0, 1440))).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "            for _ in range(n_customers)\n",
    "        ],\n",
    "        'transaction_count_30d': np.random.poisson(15, n_customers).astype(float),\n",
    "        'total_amount_30d': np.random.gamma(shape=2, scale=500, size=n_customers),\n",
    "        'avg_transaction_amount': np.random.gamma(shape=2, scale=100, size=n_customers),\n",
    "        'merchant_category_mode': np.random.choice(\n",
    "            ['retail', 'grocery', 'gas', 'restaurant', 'online'], \n",
    "            n_customers\n",
    "        ),\n",
    "        'distance_from_home_avg': np.abs(np.random.normal(10, 15, n_customers)),\n",
    "        'is_high_risk': np.random.choice([0, 1], n_customers, p=[0.95, 0.05])\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Ajouter quelques clients à haut risque avec patterns suspects\n",
    "    high_risk_indices = df[df['is_high_risk'] == 1].index\n",
    "    df.loc[high_risk_indices, 'transaction_count_30d'] *= 2\n",
    "    df.loc[high_risk_indices, 'distance_from_home_avg'] *= 3\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate the dataset\n",
    "print(\"Generating customer feature dataset...\")\n",
    "customers_df = generate_customer_features(n_customers=1000)\n",
    "\n",
    "print(f\"Dataset created with shape: {customers_df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "customers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75143ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze dataset characteristics\n",
    "print(\"Descriptive statistics:\\n\")\n",
    "print(customers_df.describe())\n",
    "\n",
    "print(\"\\nRisk distribution:\")\n",
    "print(customers_df['is_high_risk'].value_counts())\n",
    "print(f\"\\nHigh-risk customer percentage: {customers_df['is_high_risk'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc73b70",
   "metadata": {},
   "source": [
    "## Section 3: Feature Group Creation\n",
    "\n",
    "A Feature Group in SageMaker serves as a logical collection of features that are stored together and share a common schema. The Feature Group provides both online and offline access patterns.\n",
    "\n",
    "### Creation Process\n",
    "\n",
    "The process involves four steps:\n",
    "1. Define the feature schema with appropriate data types\n",
    "2. Create the Feature Group with both online and offline storage enabled\n",
    "3. Wait for the infrastructure provisioning (typically 1-2 minutes)\n",
    "4. Verify the creation status\n",
    "\n",
    "### Storage Backends\n",
    "\n",
    "SageMaker Feature Store provides two storage backends optimized for different access patterns:\n",
    "\n",
    "**Online Store (DynamoDB)**\n",
    "- Low-latency access (sub-10ms)\n",
    "- Stores most recent feature values\n",
    "- Optimized for real-time inference\n",
    "- Cost based on read/write request units\n",
    "\n",
    "**Offline Store (S3 + Glue)**\n",
    "- Higher latency (batch access)\n",
    "- Stores complete historical record\n",
    "- Optimized for model training and analytics\n",
    "- Cost based on storage volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Étape 1: Définir le Feature Group\n",
    "# ============================================================\n",
    "\n",
    "# Generate unique Feature Group name with timestamp\n",
    "feature_group_name = f\"customer-features-{int(time.time())}\"\n",
    "\n",
    "print(f\"Creating Feature Group: {feature_group_name}\")\n",
    "\n",
    "# Instantiate Feature Group object\n",
    "customer_feature_group = FeatureGroup(\n",
    "    name=feature_group_name,\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "print(\"Feature Group object instantiated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5857ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Étape 2: Charger les Feature Definitions\n",
    "# ============================================================\n",
    "\n",
    "# Infer feature definitions from DataFrame schema\n",
    "customer_feature_group.load_feature_definitions(data_frame=customers_df)\n",
    "\n",
    "print(\"Feature definitions loaded from DataFrame\")\n",
    "print(\"\\nFeature Group schema:\")\n",
    "for feature_def in customer_feature_group.feature_definitions:\n",
    "    print(f\"  - {feature_def.feature_name:30s} : {feature_def.feature_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275e150",
   "metadata": {},
   "source": [
    "### Understanding Feature Definitions\n",
    "\n",
    "**Feature Definitions** define the Feature Store schema:\n",
    "\n",
    "- `FeatureTypeEnum.STRING`: Text (customer_id, category, etc.)\n",
    "- `FeatureTypeEnum.INTEGRAL`: Integers (is_high_risk, count, etc.)\n",
    "- `FeatureTypeEnum.FRACTIONAL`: Decimal numbers (amounts, ratios, etc.)\n",
    "\n",
    "**Important notes:**\n",
    "- The schema is **immutable** after creation\n",
    "- `customer_id` and `event_time` are required\n",
    "- Types must match the ingested data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bde6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Étape 3: Créer le Feature Group (Online + Offline)\n",
    "# ============================================================\n",
    "\n",
    "print(\"Creating Feature Group (takes 1-2 minutes)...\")\n",
    "print(\"   - Online Store (DynamoDB): for real-time inference\")\n",
    "print(\"   - Offline Store (S3): for training and analytics\")\n",
    "\n",
    "# Create the Feature Group with both stores\n",
    "customer_feature_group.create(\n",
    "    s3_uri=f\"s3://{bucket}/feature-store/customer-features\",\n",
    "    record_identifier_name=\"customer_id\",\n",
    "    event_time_feature_name=\"event_time\",\n",
    "    role_arn=role,\n",
    "    enable_online_store=True  # Enable Online Store (DynamoDB)\n",
    ")\n",
    "\n",
    "print(\"\\nWaiting for Feature Group creation...\")\n",
    "print(\"   (You can monitor in Console: SageMaker > Feature Store)\")\n",
    "\n",
    "# Attendre que le Feature Group soit créé\n",
    "status = customer_feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "while status == \"Creating\":\n",
    "    print(f\"   Status: {status} ... (attente 15s)\")\n",
    "    time.sleep(15)\n",
    "    status = customer_feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "\n",
    "print(f\"\\nFeature Group created successfully.\")\n",
    "print(f\"   Status: {status}\")\n",
    "print(f\"   Online Store: Enabled (DynamoDB)\")\n",
    "print(f\"   Offline Store: Enabled (S3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb65ff",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Data Ingestion\n",
    "\n",
    "### Méthodes d'Ingestion\n",
    "\n",
    "1. **DataFrame.ingest()** : Batch ingestion (ce qu'on utilise ici)\n",
    "2. **put_record()** : Ingestion unitaire temps réel\n",
    "3. **Streaming** : Kinesis Data Streams → Feature Store\n",
    "\n",
    "### Processus d'Ingestion\n",
    "\n",
    "```\n",
    "DataFrame → Feature Group → Online Store (DynamoDB)\n",
    "                         └→ Offline Store (S3)\n",
    "```\n",
    "\n",
    "**Temps d'ingestion** :\n",
    "- Online Store : Disponible immédiatement (< 1s)\n",
    "- Offline Store : Disponible après 15-30 minutes (batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d186fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Ingestion des Données dans le Feature Store\n",
    "# ============================================================\n",
    "\n",
    "print(\"Ingesting data into Feature Store...\")\n",
    "print(f\"   Number of records: {len(customers_df)}\")\n",
    "\n",
    "# Ingest the data\n",
    "customer_feature_group.ingest(\n",
    "    data_frame=customers_df,\n",
    "    max_workers=3,  # Parallelism\n",
    "    wait=True       # Wait for ingestion to complete\n",
    ")\n",
    "\n",
    "print(\"Ingestion complete.\")\n",
    "print(\"\\nData is now available in:\")\n",
    "print(\"   - Online Store (DynamoDB): Available immediately for inference\")\n",
    "print(\"   - Offline Store (S3): Available after 15-30 minutes for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5839ec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Feature Retrieval from Online Store\n",
    "\n",
    "### Get Record : Récupération Unitaire\n",
    "\n",
    "Utile pour **inference temps réel** :\n",
    "- Latence < 10ms\n",
    "- Récupère la **dernière version** de chaque feature\n",
    "- Utilise `record_identifier` (customer_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa1d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Récupération d'un Record Unique (Online Store)\n",
    "# ============================================================\n",
    "\n",
    "# Wait for Online Store to be ready\n",
    "print(\"Waiting for Online Store to be ready (a few seconds)...\")\n",
    "time.sleep(10)\n",
    "\n",
    "# Retrieve a specific customer\n",
    "test_customer_id = \"CUST_000001\"\n",
    "\n",
    "print(f\"Retrieving features for customer: {test_customer_id}\")\n",
    "\n",
    "try:\n",
    "    # Retrieve the record from Online Store\n",
    "    record = customer_feature_group.get_record(\n",
    "        record_identifier_value_as_string=test_customer_id\n",
    "    )\n",
    "    \n",
    "    print(\"Record retrieved from Online Store:\")\n",
    "    print(json.dumps(record, indent=2))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Warning: Error (normal if ingestion is very recent): {e}\")\n",
    "    print(\"   Retry in a few seconds...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb2190c",
   "metadata": {},
   "source": [
    "### Real-World Use Case: Inference with Feature Store\n",
    "\n",
    "```python\n",
    "# Dans une lambda d'inference en production :\n",
    "\n",
    "def predict(customer_id):\n",
    "    # 1. Récupérer features depuis Feature Store (< 10ms)\n",
    "    features = feature_group.get_record(\n",
    "        record_identifier_value_as_string=customer_id\n",
    "    )\n",
    "    \n",
    "    # 2. Transformer en format modèle\n",
    "    feature_vector = extract_features(features)\n",
    "    \n",
    "    # 3. Prédire avec le modèle\n",
    "    prediction = model.predict(feature_vector)\n",
    "    \n",
    "    return prediction\n",
    "```\n",
    "\n",
    "**Advantages:**\n",
    "- No need to recompute features (already calculated)\n",
    "- Consistency between training and inference\n",
    "- Low latency (< 10ms)\n",
    "- Up-to-date features (real-time updates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79139f4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Batch Retrieval from Offline Store\n",
    "\n",
    "### Offline Store : Queries Athena\n",
    "\n",
    "L'Offline Store utilise **AWS Glue** et **Amazon Athena** pour des queries SQL.\n",
    "\n",
    "**Use Cases** :\n",
    "- Training de modèles (datasets complets)\n",
    "- Analyses historiques\n",
    "- Time-travel queries (point-in-time correctness)\n",
    "- Feature engineering exploratoire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a015492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Préparer une Query Athena pour l'Offline Store\n",
    "# ============================================================\n",
    "\n",
    "# Obtenir le nom de la table Glue\n",
    "feature_store_table = customer_feature_group.describe().get(\"OfflineStoreConfig\", {}).get(\"DataCatalogConfig\", {}).get(\"TableName\")\n",
    "\n",
    "print(f\"Offline Store table (AWS Glue): {feature_store_table}\")\n",
    "print(f\"\\nThe Offline Store is available via Athena:\")\n",
    "print(f\"   Database: sagemaker_featurestore\")\n",
    "print(f\"   Table: {feature_store_table}\")\n",
    "print(f\"\\nNote: Data takes 15-30 minutes to appear in the Offline Store\")\n",
    "print(f\"      (batch processing from DynamoDB to S3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dbdefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Exemple de Query Athena (après 15-30 min)\n",
    "# ============================================================\n",
    "\n",
    "# Query SQL pour récupérer les customers à haut risque\n",
    "athena_query = f\"\"\"\n",
    "SELECT \n",
    "    customer_id,\n",
    "    transaction_count_30d,\n",
    "    total_amount_30d,\n",
    "    avg_transaction_amount,\n",
    "    distance_from_home_avg,\n",
    "    is_high_risk\n",
    "FROM \n",
    "    \"{feature_store_table}\"\n",
    "WHERE \n",
    "    is_high_risk = 1\n",
    "ORDER BY \n",
    "    total_amount_30d DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "print(\"Example Athena query for Offline Store:\")\n",
    "print(\"=\" * 60)\n",
    "print(athena_query)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nTo execute this query (after 15-30 minutes):\")\n",
    "print(\"\"\"\n",
    "# Option 1 : Via SageMaker SDK\n",
    "query_results = customer_feature_group.athena_query().run(\n",
    "    query_string=athena_query,\n",
    "    output_location=f's3://{bucket}/athena-results/'\n",
    ")\n",
    "\n",
    "# Option 2 : Via AWS Console\n",
    "# SageMaker → Feature Store → Offline Store → Query with Athena\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84b0196",
   "metadata": {},
   "source": [
    "### Time-Travel Queries\n",
    "\n",
    "Le Feature Store supporte les **point-in-time queries** pour éviter le data leakage :\n",
    "\n",
    "```sql\n",
    "-- Récupérer les features telles qu'elles étaient le 2024-01-01\n",
    "SELECT *\n",
    "FROM \"customer_features_table\"\n",
    "WHERE event_time <= '2024-01-01T00:00:00Z'\n",
    "```\n",
    "\n",
    "**Pourquoi c'est important ?**\n",
    "- Éviter le **data leakage** (utiliser des features du futur)\n",
    "- Reproduire exactement le contexte d'entraînement\n",
    "- Débugger des problèmes de modèle en production\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a99642d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 7: Model Packaging\n",
    "\n",
    "Maintenant que nous avons nos features, entraînons un modèle simple et **packageons-le** correctement.\n",
    "\n",
    "### Qu'est-ce que le Model Packaging ?\n",
    "\n",
    "**But** : Créer un artifact déployable sur SageMaker contenant :\n",
    "1. Le modèle entraîné (`.pkl`, `.pth`, etc.)\n",
    "2. Le code d'inference (`inference.py`)\n",
    "3. Les dépendances (`requirements.txt`)\n",
    "4. Metadata et configuration\n",
    "\n",
    "### Structure d'un Package Modèle\n",
    "\n",
    "```\n",
    "model.tar.gz\n",
    "├── model.pkl              # Modèle sérialisé\n",
    "├── code/\n",
    "│   ├── inference.py       # Code d'inference custom\n",
    "│   └── requirements.txt   # Dépendances Python\n",
    "└── metadata.json          # (optionnel) Métadonnées\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c942e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Entraîner un Modèle Simple\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "print(\"Training risk detection model...\")\n",
    "\n",
    "# Préparer les features\n",
    "X = customers_df[[\n",
    "    'transaction_count_30d',\n",
    "    'total_amount_30d',\n",
    "    'avg_transaction_amount',\n",
    "    'distance_from_home_avg'\n",
    "]].values\n",
    "\n",
    "y = customers_df['is_high_risk'].values\n",
    "\n",
    "# Encoder la feature catégorielle\n",
    "le = LabelEncoder()\n",
    "merchant_encoded = le.fit_transform(customers_df['merchant_category_mode'])\n",
    "X_with_merchant = np.column_stack([X, merchant_encoded])\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_with_merchant, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Entraîner\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'  # Important pour classes déséquilibrées\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluer\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nModel performance:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Low Risk', 'High Risk']))\n",
    "print(f\"ROC AUC Score : {roc_auc_score(y_test, y_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4255e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Créer le Répertoire de Packaging\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Créer répertoire pour le package\n",
    "model_dir = \"model_package\"\n",
    "code_dir = os.path.join(model_dir, \"code\")\n",
    "\n",
    "# Nettoyer si existe déjà\n",
    "if os.path.exists(model_dir):\n",
    "    shutil.rmtree(model_dir)\n",
    "\n",
    "os.makedirs(code_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Directory created: {model_dir}/\")\n",
    "print(f\"   Structure:\")\n",
    "print(f\"   {model_dir}/\")\n",
    "print(f\"   ├── model.pkl\")\n",
    "print(f\"   ├── label_encoder.pkl\")\n",
    "print(f\"   └── code/\")\n",
    "print(f\"       ├── inference.py\")\n",
    "print(f\"       └── requirements.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0ad105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Sauvegarder le Modèle et l'Encodeur\n",
    "# ============================================================\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "model_path = os.path.join(model_dir, \"model.pkl\")\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"Model saved: {model_path}\")\n",
    "\n",
    "# Save the label encoder\n",
    "encoder_path = os.path.join(model_dir, \"label_encoder.pkl\")\n",
    "joblib.dump(le, encoder_path)\n",
    "print(f\"Encoder saved: {encoder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aec2f45",
   "metadata": {},
   "source": [
    "### Creating the Inference Script\n",
    "\n",
    "Le script `inference.py` doit définir ces fonctions :\n",
    "\n",
    "1. **`model_fn(model_dir)`** : Charger le modèle depuis le disque\n",
    "2. **`input_fn(request_body, content_type)`** : Parser les requêtes entrantes\n",
    "3. **`predict_fn(input_data, model)`** : Effectuer la prédiction\n",
    "4. **`output_fn(prediction, accept_type)`** : Formater la réponse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bef592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Créer inference.py\n",
    "# ============================================================\n",
    "\n",
    "inference_code = '''\n",
    "\"\"\"\n",
    "Script d'inference personnalisé pour SageMaker\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Charge le modèle depuis le répertoire du modèle.\n",
    "    \n",
    "    Cette fonction est appelée une seule fois au démarrage de l'endpoint.\n",
    "    \n",
    "    Args:\n",
    "        model_dir : Chemin vers le répertoire contenant les artifacts\n",
    "        \n",
    "    Returns:\n",
    "        dict : Dictionnaire contenant le modèle et l'encodeur\n",
    "    \"\"\"\n",
    "    print(f\"Loading model from {model_dir}\")\n",
    "    \n",
    "    model = joblib.load(os.path.join(model_dir, \"model.pkl\"))\n",
    "    label_encoder = joblib.load(os.path.join(model_dir, \"label_encoder.pkl\"))\n",
    "    \n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"label_encoder\": label_encoder\n",
    "    }\n",
    "\n",
    "def input_fn(request_body, content_type):\n",
    "    \"\"\"\n",
    "    Parse les données d'entrée depuis la requête.\n",
    "    \n",
    "    Args:\n",
    "        request_body : Corps de la requête (bytes ou string)\n",
    "        content_type : Type MIME de la requête\n",
    "        \n",
    "    Returns:\n",
    "        dict : Données parsées\n",
    "    \"\"\"\n",
    "    if content_type == \"application/json\":\n",
    "        data = json.loads(request_body)\n",
    "        return data\n",
    "    else:\n",
    "        raise ValueError(f\"Content type {content_type} not supported\")\n",
    "\n",
    "def predict_fn(input_data, model_dict):\n",
    "    \"\"\"\n",
    "    Effectue la prédiction.\n",
    "    \n",
    "    Args:\n",
    "        input_data : Données d'entrée (dict)\n",
    "        model_dict : Dict contenant model et label_encoder\n",
    "        \n",
    "    Returns:\n",
    "        dict : Résultat de la prédiction\n",
    "    \"\"\"\n",
    "    model = model_dict[\"model\"]\n",
    "    label_encoder = model_dict[\"label_encoder\"]\n",
    "    \n",
    "    # Extraire les features\n",
    "    transaction_count = input_data.get(\"transaction_count_30d\", 0)\n",
    "    total_amount = input_data.get(\"total_amount_30d\", 0)\n",
    "    avg_amount = input_data.get(\"avg_transaction_amount\", 0)\n",
    "    distance = input_data.get(\"distance_from_home_avg\", 0)\n",
    "    merchant_category = input_data.get(\"merchant_category_mode\", \"retail\")\n",
    "    \n",
    "    # Encoder la catégorie\n",
    "    try:\n",
    "        merchant_encoded = label_encoder.transform([merchant_category])[0]\n",
    "    except:\n",
    "        merchant_encoded = 0  # Valeur par défaut si catégorie inconnue\n",
    "    \n",
    "    # Créer le vecteur de features\n",
    "    features = np.array([[\n",
    "        transaction_count,\n",
    "        total_amount,\n",
    "        avg_amount,\n",
    "        distance,\n",
    "        merchant_encoded\n",
    "    ]])\n",
    "    \n",
    "    # Prédire\n",
    "    prediction = model.predict(features)[0]\n",
    "    probability = model.predict_proba(features)[0]\n",
    "    \n",
    "    return {\n",
    "        \"is_high_risk\": int(prediction),\n",
    "        \"risk_probability\": float(probability[1]),\n",
    "        \"confidence\": float(max(probability))\n",
    "    }\n",
    "\n",
    "def output_fn(prediction, accept_type):\n",
    "    \"\"\"\n",
    "    Formate la sortie de la prédiction.\n",
    "    \n",
    "    Args:\n",
    "        prediction : Résultat de predict_fn\n",
    "        accept_type : Type MIME de réponse attendu\n",
    "        \n",
    "    Returns:\n",
    "        tuple : (réponse formatée, content_type)\n",
    "    \"\"\"\n",
    "    if accept_type == \"application/json\":\n",
    "        return json.dumps(prediction), accept_type\n",
    "    else:\n",
    "        raise ValueError(f\"Accept type {accept_type} not supported\")\n",
    "'''\n",
    "\n",
    "# Écrire le fichier\n",
    "inference_path = os.path.join(code_dir, \"inference.py\")\n",
    "with open(inference_path, \"w\") as f:\n",
    "    f.write(inference_code)\n",
    "\n",
    "print(f\"Inference script created: {inference_path}\")\n",
    "print(f\"\\nThe script contains:\")\n",
    "print(f\"   - model_fn(): Loads the model at startup\")\n",
    "print(f\"   - input_fn(): Parses JSON requests\")\n",
    "print(f\"   - predict_fn(): Performs prediction\")\n",
    "print(f\"   - output_fn(): Formats the response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fecc936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Créer requirements.txt\n",
    "# ============================================================\n",
    "\n",
    "requirements = '''scikit-learn==1.3.0\n",
    "numpy==1.24.3\n",
    "joblib==1.3.1\n",
    "'''\n",
    "\n",
    "requirements_path = os.path.join(code_dir, \"requirements.txt\")\n",
    "with open(requirements_path, \"w\") as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "print(f\"Dependencies file created: {requirements_path}\")\n",
    "print(f\"\\nRequired packages:\")\n",
    "print(requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa55cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Créer model.tar.gz\n",
    "# ============================================================\n",
    "\n",
    "import tarfile\n",
    "\n",
    "# Créer l'archive\n",
    "tar_path = \"model.tar.gz\"\n",
    "\n",
    "with tarfile.open(tar_path, \"w:gz\") as tar:\n",
    "    tar.add(model_dir, arcname=\".\")\n",
    "\n",
    "print(f\"Package created: {tar_path}\")\n",
    "\n",
    "# Verify contents\n",
    "print(f\"\\nContents of {tar_path}:\")\n",
    "with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "    for member in tar.getmembers():\n",
    "        print(f\"   {member.name:40s} ({member.size} bytes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7af7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Uploader vers S3\n",
    "# ============================================================\n",
    "\n",
    "# Uploader le model package vers S3\n",
    "model_s3_key = f\"lab5-models/risk-detection/model.tar.gz\"\n",
    "model_s3_uri = f\"s3://{bucket}/{model_s3_key}\"\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "s3_client.upload_file(tar_path, bucket, model_s3_key)\n",
    "\n",
    "print(f\"Model uploaded to S3:\")\n",
    "print(f\"   {model_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6683d2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 8: Model Registry\n",
    "\n",
    "### Qu'est-ce que le Model Registry ?\n",
    "\n",
    "Le **Model Registry** est un catalogue centralisé de modèles ML qui permet :\n",
    "\n",
    "1. **Versioning** : Gérer plusieurs versions d'un modèle\n",
    "2. **Approval Workflow** : Pending → Approved → Rejected\n",
    "3. **Metadata** : Stocker métriques, datasets, paramètres\n",
    "4. **Lineage** : Tracer l'origine du modèle (data + code)\n",
    "5. **Deployment** : Source pour déploiement en production\n",
    "\n",
    "### Architecture du Model Registry\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────┐\n",
    "│              Model Package Group                        │\n",
    "│          (ex: \"fraud-detection-models\")                │\n",
    "│                                                          │\n",
    "│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐ │\n",
    "│  │  Version 1   │  │  Version 2   │  │  Version 3   │ │\n",
    "│  │  (Approved)  │  │  (Pending)   │  │  (Rejected)  │ │\n",
    "│  │  AUC: 0.85   │  │  AUC: 0.92   │  │  AUC: 0.80   │ │\n",
    "│  └──────────────┘  └──────────────┘  └──────────────┘ │\n",
    "└────────────────────────────────────────────────────────┘\n",
    "          ↓                  ↓                  ↓\n",
    "      Production         Staging            Archived\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e3c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Créer un Model Package Group\n",
    "# ============================================================\n",
    "\n",
    "from sagemaker.model import Model\n",
    "\n",
    "# Nom du Model Package Group\n",
    "model_package_group_name = \"customer-risk-detection-models\"\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "# Créer le Model Package Group\n",
    "try:\n",
    "    sm_client.create_model_package_group(\n",
    "        ModelPackageGroupName=model_package_group_name,\n",
    "        ModelPackageGroupDescription=\"Modèles de détection de risque client pour prévention fraude\"\n",
    "    )\n",
    "    print(f\"Model Package Group created: {model_package_group_name}\")\n",
    "except sm_client.exceptions.ResourceInUse:\n",
    "    print(f\"Note: Model Package Group already exists: {model_package_group_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0383e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Enregistrer le Modèle dans le Registry\n",
    "# ============================================================\n",
    "\n",
    "from sagemaker.sklearn import SKLearnModel\n",
    "from sagemaker.model_metrics import ModelMetrics, MetricsSource\n",
    "\n",
    "# Créer l'objet Model\n",
    "sklearn_model = SKLearnModel(\n",
    "    model_data=model_s3_uri,\n",
    "    role=role,\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=code_dir,\n",
    "    framework_version=\"1.2-1\",  # Version de scikit-learn\n",
    "    py_version=\"py3\"\n",
    ")\n",
    "\n",
    "print(\"Registering model in Model Registry...\")\n",
    "print(f\"   Model Package Group: {model_package_group_name}\")\n",
    "print(f\"   Model Data: {model_s3_uri}\")\n",
    "\n",
    "# Créer les métriques du modèle (optionnel mais recommandé)\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=f\"s3://{bucket}/model-metrics/metrics.json\",\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Enregistrer dans le Model Registry\n",
    "model_package = sklearn_model.register(\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=\"PendingManualApproval\",  # En attente d'approbation\n",
    "    description=\"Random Forest model for customer risk detection (Lab 5)\",\n",
    "    model_metrics=model_metrics\n",
    ")\n",
    "\n",
    "print(f\"\\nModel registered in Model Registry successfully.\")\n",
    "print(f\"   Model Package ARN: {model_package.model_package_arn}\")\n",
    "print(f\"   Status: PendingManualApproval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c05104",
   "metadata": {},
   "source": [
    "### Approval Workflow\n",
    "\n",
    "Le modèle passe par ces états :\n",
    "\n",
    "1. **PendingManualApproval** : En attente de review\n",
    "2. **Approved** : Validé pour production\n",
    "3. **Rejected** : Refusé (ne pas déployer)\n",
    "\n",
    "**Qui approuve ?**\n",
    "- ML Engineer lead\n",
    "- Product Owner\n",
    "- Compliance team (pour cas sensibles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e8a540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Approuver le Modèle\n",
    "# ============================================================\n",
    "\n",
    "print(\"Approving model for deployment...\")\n",
    "\n",
    "# Mettre à jour le status à \"Approved\"\n",
    "sm_client.update_model_package(\n",
    "    ModelPackageArn=model_package.model_package_arn,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    "    ApprovalDescription=\"Model validated by ML team. ROC AUC = 0.92, ready for production.\"\n",
    ")\n",
    "\n",
    "print(f\"Model approved.\")\n",
    "print(f\"   The model can now be deployed to production.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c136f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Lister les Modèles dans le Registry\n",
    "# ============================================================\n",
    "\n",
    "print(f\"Models registered in group: {model_package_group_name}\\n\")\n",
    "\n",
    "response = sm_client.list_model_packages(\n",
    "    ModelPackageGroupName=model_package_group_name,\n",
    "    SortBy=\"CreationTime\",\n",
    "    SortOrder=\"Descending\"\n",
    ")\n",
    "\n",
    "for i, package in enumerate(response['ModelPackageSummaryList'], 1):\n",
    "    print(f\"{i}. Version: {package['ModelPackageVersion']}\")\n",
    "    print(f\"   ARN: {package['ModelPackageArn']}\")\n",
    "    print(f\"   Status: {package['ModelApprovalStatus']}\")\n",
    "    print(f\"   Created: {package['CreationTime']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e61afc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 9: Deploy from Model Registry\n",
    "\n",
    "Maintenant que le modèle est **approuvé**, déployons-le directement depuis le Registry.\n",
    "\n",
    "### Avantages de Déployer depuis le Registry\n",
    "\n",
    "1. **Traçabilité** : Savoir exactement quelle version est en production\n",
    "2. **Governance** : Seuls les modèles approuvés peuvent être déployés\n",
    "3. **Rollback facile** : Revenir à une version précédente rapidement\n",
    "4. **Audit** : Log complet des déploiements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acccde74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Déployer le Modèle Approuvé\n",
    "# ============================================================\n",
    "\n",
    "from sagemaker.model import ModelPackage\n",
    "\n",
    "print(\"Deploying model from Model Registry...\")\n",
    "\n",
    "# Create a ModelPackage object from the Registry\n",
    "model_package_predictor = ModelPackage(\n",
    "    role=role,\n",
    "    model_package_arn=model_package.model_package_arn,\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "# Deploy to an endpoint\n",
    "endpoint_name = f\"risk-detection-{int(time.time())}\"\n",
    "\n",
    "print(f\"   Endpoint name: {endpoint_name}\")\n",
    "print(f\"   Instance type: ml.t2.medium\")\n",
    "print(f\"   Deployment in progress (3-5 minutes)...\")\n",
    "\n",
    "predictor = model_package_predictor.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.t2.medium\",\n",
    "    endpoint_name=endpoint_name\n",
    ")\n",
    "\n",
    "print(f\"\\nEndpoint deployed successfully.\")\n",
    "print(f\"   Endpoint: {endpoint_name}\")\n",
    "print(f\"   Status: InService\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ab47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Tester l'Endpoint\n",
    "# ============================================================\n",
    "\n",
    "# Données de test\n",
    "test_data = {\n",
    "    \"transaction_count_30d\": 25.0,\n",
    "    \"total_amount_30d\": 2500.0,\n",
    "    \"avg_transaction_amount\": 100.0,\n",
    "    \"distance_from_home_avg\": 50.0,\n",
    "    \"merchant_category_mode\": \"online\"\n",
    "}\n",
    "\n",
    "print(\"Testing endpoint with sample data...\")\n",
    "print(f\"\\nInput:\")\n",
    "print(json.dumps(test_data, indent=2))\n",
    "\n",
    "# Predict\n",
    "result = predictor.predict(test_data)\n",
    "\n",
    "print(f\"\\nPrediction result:\")\n",
    "print(json.dumps(result, indent=2))\n",
    "\n",
    "if result['is_high_risk'] == 1:\n",
    "    print(f\"\\nALERT: HIGH RISK customer\")\n",
    "    print(f\"   Risk probability: {result['risk_probability']*100:.1f}%\")\n",
    "else:\n",
    "    print(f\"\\nLow risk customer\")\n",
    "    print(f\"   Risk probability: {result['risk_probability']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a40f9e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 10: Resource Cleanup\n",
    "\n",
    "**Important:** To avoid unnecessary costs, delete the created resources.\n",
    "\n",
    "### Ressources à Nettoyer\n",
    "\n",
    "1. **Endpoint** : $0.05-0.10/heure (coût continu)\n",
    "2. **Feature Group** : $0.025/GB/mois (Online Store)\n",
    "3. **Model Package** : Gratuit (sauf stockage S3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e86171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Nettoyer l'Endpoint\n",
    "# ============================================================\n",
    "\n",
    "print(\"Cleaning up endpoint...\")\n",
    "\n",
    "try:\n",
    "    predictor.delete_endpoint()\n",
    "    print(f\"Endpoint deleted: {endpoint_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Error during deletion: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0041ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Nettoyer le Feature Group (Optionnel)\n",
    "# ============================================================\n",
    "\n",
    "print(\"Note: Deleting Feature Group...\")\n",
    "print(\"   WARNING: This will delete ALL ingested data!\")\n",
    "\n",
    "# Uncomment to delete:\n",
    "# customer_feature_group.delete()\n",
    "# print(f\"Feature Group deleted: {feature_group_name}\")\n",
    "\n",
    "print(\"\\nFeature Group preserved for use in subsequent labs\")\n",
    "print(f\"   To delete manually: Console > SageMaker > Feature Store)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d2151c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Key Learnings\n",
    "\n",
    "### What You Accomplished\n",
    "\n",
    "1. **Feature Store**:\n",
    "   - Created a Feature Group with Online + Offline stores\n",
    "   - Ingested 1000 records\n",
    "   - Retrieved features for inference (<10ms)\n",
    "   - Understood the architecture: Online (DynamoDB) vs Offline (S3)\n",
    "\n",
    "2. **Model Packaging**:\n",
    "   - Packaged a scikit-learn model with dependencies\n",
    "   - Created a custom inference script (inference.py)\n",
    "   - Generated proper model.tar.gz for SageMaker\n",
    "   - Uploaded to S3\n",
    "\n",
    "3. **Model Registry**:\n",
    "   - Created a Model Package Group\n",
    "   - Registered a model with metadata\n",
    "   - Implemented an approval workflow\n",
    "   - Deployed from the Registry\n",
    "\n",
    "4. **Deployment**:\n",
    "   - Deployed an endpoint from the Model Registry\n",
    "   - Tested real-time inference\n",
    "   - Understood traceability and governance\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "| Concept | Définition | Use Case |\n",
    "|---------|------------|----------|\n",
    "| **Feature Store** | Catalogue centralisé de features | Training + Inference consistency |\n",
    "| **Online Store** | DynamoDB, <10ms latency | Real-time inference |\n",
    "| **Offline Store** | S3 + Glue, batch queries | Training, analytics |\n",
    "| **Model Registry** | Catalogue de modèles versionnés | Governance, approval workflow |\n",
    "| **model.tar.gz** | Package déployable sur SageMaker | Modèle + code + dependencies |\n",
    "| **inference.py** | Script custom pour inference | Preprocessing, postprocessing |\n",
    "\n",
    "### Complete Architecture Built\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────┐\n",
    "│                   Feature Store                         │\n",
    "│  ┌──────────────┐              ┌──────────────┐        │\n",
    "│  │Online Store  │              │Offline Store │        │\n",
    "│  │(DynamoDB)    │              │(S3 + Glue)   │        │\n",
    "│  └──────────────┘              └──────────────┘        │\n",
    "└─────────────────────────────────────────────────────────┘\n",
    "         ↓                                ↓\n",
    "         |                                |\n",
    "    Inference                         Training\n",
    "         |                                |\n",
    "         ↓                                ↓\n",
    "┌─────────────────────────────────────────────────────────┐\n",
    "│                   Model Registry                        │\n",
    "│                                                          │\n",
    "│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐ │\n",
    "│  │  Version 1   │  │  Version 2   │  │  Version 3   │ │\n",
    "│  │  (Approved)  │  │  (Pending)   │  │  (Approved)  │ │\n",
    "│  └──────────────┘  └──────────────┘  └──────────────┘ │\n",
    "└─────────────────────────────────────────────────────────┘\n",
    "         ↓\n",
    "         |\n",
    "    Deployment\n",
    "         ↓\n",
    "┌─────────────────────────────────────────────────────────┐\n",
    "│                   SageMaker Endpoint                    │\n",
    "│                   (Real-time Inference)                  │\n",
    "└─────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "**Lab 6**: Advanced deployment (Serverless, Async, Multi-Model Endpoints)\n",
    "\n",
    "**Lab 7**: SageMaker Pipelines for MLOps automation\n",
    "\n",
    "**Lab 8**: Model Monitor and deployment strategies\n",
    "\n",
    "---\n",
    "\n",
    "## Reflection Questions\n",
    "\n",
    "1. **Why** use a Feature Store instead of computing features each time?\n",
    "2. **What is** the difference between Online Store and Offline Store?\n",
    "3. **How** does the Model Registry improve governance?\n",
    "4. **Why** package the model with inference.py instead of the model alone?\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [Feature Store Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store.html)\n",
    "- [Model Registry Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html)\n",
    "- [Inference Code Examples](https://github.com/aws/amazon-sagemaker-examples)\n",
    "- [MLOps Best Practices](https://docs.aws.amazon.com/sagemaker/latest/dg/best-practices.html)\n",
    "\n",
    "---\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "You have successfully completed Lab 5! You now master:\n",
    "- SageMaker Feature Store (Online + Offline)\n",
    "- Model Packaging and inference scripts\n",
    "- Model Registry and approval workflows\n",
    "- ✅ Déploiement depuis le Registry\n",
    "\n",
    "**Temps de pause recommandé : 15 minutes ☕**\n",
    "\n",
    "Ensuite, passez au **Lab 6** pour découvrir les différents types d'endpoints et stratégies de déploiement avancées !\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
