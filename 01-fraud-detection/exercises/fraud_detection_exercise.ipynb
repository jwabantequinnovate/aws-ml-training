{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection Exercise\n",
    "\n",
    "## Objective\n",
    "Build and deploy a fraud detection model using AWS SageMaker with focus on handling imbalanced data.\n",
    "\n",
    "## Tasks Overview\n",
    "1. Data Generation and Exploration\n",
    "2. Feature Engineering\n",
    "3. Handle Imbalanced Data\n",
    "4. Model Training and Comparison\n",
    "5. Model Evaluation\n",
    "6. Model Explainability\n",
    "7. SageMaker Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Data Generation and Exploration\n",
    "\n",
    "### TODO:\n",
    "- Generate synthetic fraud detection dataset\n",
    "- Explore the dataset structure\n",
    "- Analyze class distribution\n",
    "- Visualize key features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic fraud detection data\n",
    "def generate_fraud_dataset(n_samples=100000, fraud_ratio=0.02):\n",
    "    \"\"\"\n",
    "    TODO: Complete this function to generate synthetic fraud data\n",
    "    \n",
    "    Features to include:\n",
    "    - transaction_amount: Transaction amount\n",
    "    - hour_of_day: Hour when transaction occurred\n",
    "    - day_of_week: Day of week\n",
    "    - merchant_category: Type of merchant\n",
    "    - distance_from_home: Distance from home address\n",
    "    - distance_from_last_transaction: Distance from previous transaction\n",
    "    - transaction_velocity: Number of transactions in last hour\n",
    "    - is_fraud: Target variable\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Generated dataset\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Generate dataset\n",
    "df = generate_fraud_dataset(n_samples=100000, fraud_ratio=0.02)\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze class distribution\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize feature distributions for fraud vs non-fraud\n",
    "# Create visualizations comparing features between fraud and legitimate transactions\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Feature Engineering\n",
    "\n",
    "### TODO:\n",
    "- Create additional temporal features\n",
    "- Encode categorical variables\n",
    "- Create interaction features\n",
    "- Handle missing values if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Feature engineering\n",
    "# Create new features that might be useful for fraud detection\n",
    "# Examples:\n",
    "# - is_weekend\n",
    "# - is_night_transaction\n",
    "# - amount_vs_velocity_ratio\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Data Preparation and Splitting\n",
    "\n",
    "### TODO:\n",
    "- Split data into train/validation/test sets\n",
    "- Scale numerical features\n",
    "- Ensure stratification for imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Prepare features and target\n",
    "# X = ...\n",
    "# y = ...\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Split data (60% train, 20% validation, 20% test)\n",
    "# Remember to use stratification!\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Scale features\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Handle Imbalanced Data\n",
    "\n",
    "### TODO:\n",
    "- Apply SMOTE for oversampling minority class\n",
    "- Try class weight adjustments\n",
    "- Compare different strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# TODO: Apply SMOTE to training data\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Check new class distribution\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Model Training\n",
    "\n",
    "### TODO:\n",
    "- Train baseline Logistic Regression\n",
    "- Train XGBoost model\n",
    "- Train LightGBM model\n",
    "- Compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# TODO: Train Logistic Regression (baseline)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Train XGBoost\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Train LightGBM\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Model Evaluation\n",
    "\n",
    "### TODO:\n",
    "- Calculate ROC-AUC scores\n",
    "- Generate precision-recall curves\n",
    "- Create confusion matrices\n",
    "- Calculate cost-sensitive metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate all models on validation set\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Plot ROC curves\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Plot Precision-Recall curves\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate cost-sensitive metrics\n",
    "# Assume: \n",
    "# - Cost of false positive (investigating legitimate transaction): $5\n",
    "# - Cost of false negative (missing fraud): $100\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Model Explainability\n",
    "\n",
    "### TODO:\n",
    "- Calculate feature importance\n",
    "- Generate SHAP values\n",
    "- Create SHAP summary plots\n",
    "- Explain individual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# TODO: Calculate SHAP values for best model\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Create SHAP summary plot\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Explain a single fraud prediction\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: SageMaker Deployment Preparation\n",
    "\n",
    "### TODO:\n",
    "- Save the best model\n",
    "- Create inference script\n",
    "- Prepare model artifacts for SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# TODO: Save the best performing model\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Prepare for SageMaker deployment\n",
    "# - Create inference.py script\n",
    "# - Package model artifacts\n",
    "# - Upload to S3\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Deploy to SageMaker (Advanced)\n",
    "\n",
    "### TODO:\n",
    "- Create SageMaker model\n",
    "- Deploy to real-time endpoint\n",
    "- Test endpoint with sample data\n",
    "- Set up monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and deploy SageMaker endpoint\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Test endpoint\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Clean up (delete endpoint when done)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "1. What was the impact of handling class imbalance on model performance?\n",
    "2. Which model performed best and why?\n",
    "3. What are the trade-offs between precision and recall in fraud detection?\n",
    "4. How would you handle concept drift in production?\n",
    "5. What additional features might improve the model?\n",
    "\n",
    "**Write your answers here:**\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "4. \n",
    "5. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
