{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Fraud Detection avec Machine Learning\n",
    "## Solution Compl√®te\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objectifs de ce Lab\n",
    "\n",
    "Dans ce lab, vous allez apprendre √† :\n",
    "\n",
    "1. **G√©n√©rer** un dataset synth√©tique de transactions bancaires\n",
    "2. **Analyser** les donn√©es et comprendre le d√©s√©quilibre des classes\n",
    "3. **Cr√©er des features** pertinentes pour la d√©tection de fraude\n",
    "4. **G√©rer** le d√©s√©quilibre avec SMOTE (Synthetic Minority Over-sampling)\n",
    "5. **Entra√Æner** plusieurs mod√®les ML (Logistic Regression, XGBoost, LightGBM)\n",
    "6. **√âvaluer** avec des m√©triques adapt√©es (Precision, Recall, AUC)\n",
    "7. **Lancer** un SageMaker Training Job\n",
    "8. **Tracker** avec SageMaker Experiments\n",
    "9. **Enregistrer** dans le Model Registry\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Contexte Business\n",
    "\n",
    "### Le Probl√®me de la Fraude\n",
    "\n",
    "Les banques perdent des **milliards** chaque ann√©e √† cause de la fraude :\n",
    "- üá∫üá∏ USA : $28.58 milliards en 2020\n",
    "- üåç Monde : $32.39 milliards projet√©s en 2025\n",
    "\n",
    "**Types de fraude** :\n",
    "- Transactions non autoris√©es\n",
    "- Vol d'identit√©\n",
    "- Phishing et ing√©nierie sociale\n",
    "- Fraude aux marchands\n",
    "\n",
    "### Pourquoi le ML ?\n",
    "\n",
    "**Approche traditionnelle** (r√®gles) :\n",
    "```\n",
    "IF amount > 1000 AND distance > 50km THEN flag\n",
    "```\n",
    "‚ùå Trop de faux positifs\n",
    "‚ùå Les fraudeurs adaptent leurs strat√©gies\n",
    "‚ùå R√®gles manuelles difficiles √† maintenir\n",
    "\n",
    "**Approche ML** :\n",
    "‚úÖ Apprend des patterns complexes\n",
    "‚úÖ S'adapte aux nouvelles techniques de fraude\n",
    "‚úÖ Optimise Precision/Recall selon besoins business\n",
    "\n",
    "### D√©fi Principal : Classes D√©s√©quilibr√©es\n",
    "\n",
    "Typiquement : **0.1% - 1%** des transactions sont frauduleuses\n",
    "\n",
    "```\n",
    "Normal transactions: 99%  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
    "Fraudulent:           1%  ‚ñà\n",
    "```\n",
    "\n",
    "‚ö†Ô∏è **Probl√®me** : Un mod√®le qui pr√©dit toujours \"normal\" aurait 99% d'accuracy !\n",
    "\n",
    "**Solutions** :\n",
    "1. M√©triques adapt√©es (Precision, Recall, F1, AUC)\n",
    "2. Techniques de resampling (SMOTE, undersampling)\n",
    "3. Class weights dans les mod√®les\n",
    "4. Ensembles et boosting\n",
    "\n",
    "---\n",
    "\n",
    "## ‚è±Ô∏è Dur√©e Estim√©e\n",
    "\n",
    "- **Partie 1 (Exploration)** : 15 minutes\n",
    "- **Partie 2 (Feature Engineering)** : 10 minutes\n",
    "- **Partie 3 (Modeling Local)** : 25 minutes\n",
    "- **Partie 4 (SageMaker Integration)** : 20 minutes\n",
    "- **Total** : 70 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection Solution\n",
    "\n",
    "## Complete implementation with best practices\n",
    "\n",
    "This notebook provides the complete solution for the fraud detection exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Setup : Configuration de l'Environnement\n",
    "\n",
    "Commen√ßons par importer les biblioth√®ques n√©cessaires et configurer l'environnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, \n",
    "    precision_recall_curve, roc_curve, auc\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Partie 1: G√©n√©ration et Exploration des Donn√©es\n",
    "\n",
    "### Pourquoi des Donn√©es Synth√©tiques ?\n",
    "\n",
    "Pour ce lab, nous g√©n√©rons des donn√©es synth√©tiques car :\n",
    "- ‚úÖ Les vraies donn√©es de fraude sont **confidentielles**\n",
    "- ‚úÖ Permet de **contr√¥ler** les patterns et le ratio de fraude\n",
    "- ‚úÖ Pas de probl√®mes de **compliance** (RGPD, PCI-DSS)\n",
    "- ‚úÖ **Reproductible** pour l'apprentissage\n",
    "\n",
    "### Features de Transaction\n",
    "\n",
    "Nous allons cr√©er des features r√©alistes :\n",
    "\n",
    "| Feature | Description | Pattern Fraude |\n",
    "|---------|-------------|----------------|\n",
    "| `transaction_amount` | Montant en $ | ‚¨ÜÔ∏è Plus √©lev√© |\n",
    "| `hour_of_day` | Heure (0-23) | üåô Plus la nuit |\n",
    "| `day_of_week` | Jour (0-6) | ‚û°Ô∏è Pas de pattern clair |\n",
    "| `merchant_category` | Type de marchand | üíª Plus online |\n",
    "| `distance_from_home` | Distance (km) | ‚¨ÜÔ∏è Plus loin |\n",
    "| `distance_from_last_transaction` | Distance depuis derni√®re (km) | ‚¨ÜÔ∏è Plus loin |\n",
    "| `transaction_velocity` | Transactions/jour | ‚¨ÜÔ∏è Plus √©lev√©e |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fraud_dataset(n_samples=100000, fraud_ratio=0.02):\n",
    "    \"\"\"\n",
    "    Generate synthetic fraud detection dataset with realistic patterns\n",
    "    \"\"\"\n",
    "    n_fraud = int(n_samples * fraud_ratio)\n",
    "    n_legit = n_samples - n_fraud\n",
    "    \n",
    "    # Probabilities for hour of day (normalized)\n",
    "    legit_hour_probs = np.array([\n",
    "        0.01, 0.01, 0.01, 0.01, 0.01, 0.02, 0.04, 0.06,\n",
    "        0.08, 0.07, 0.06, 0.07, 0.08, 0.07, 0.06, 0.05,\n",
    "        0.04, 0.05, 0.06, 0.07, 0.06, 0.04, 0.03, 0.02\n",
    "    ])\n",
    "    legit_hour_probs = legit_hour_probs / legit_hour_probs.sum()\n",
    "    \n",
    "    fraud_hour_probs = np.array([\n",
    "        0.08, 0.08, 0.07, 0.06, 0.05, 0.03, 0.02, 0.02,\n",
    "        0.02, 0.02, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03,\n",
    "        0.03, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.08\n",
    "    ])\n",
    "    fraud_hour_probs = fraud_hour_probs / fraud_hour_probs.sum()\n",
    "    \n",
    "    # Legitimate transactions\n",
    "    legit_data = {\n",
    "        'transaction_amount': np.random.gamma(2, 50, n_legit),\n",
    "        'hour_of_day': np.random.choice(range(24), n_legit, p=legit_hour_probs),\n",
    "        'day_of_week': np.random.randint(0, 7, n_legit),\n",
    "        'merchant_category': np.random.choice(\n",
    "            ['retail', 'grocery', 'gas', 'restaurant', 'online'],\n",
    "            n_legit\n",
    "        ),\n",
    "        'distance_from_home': np.abs(np.random.normal(5, 10, n_legit)),\n",
    "        'distance_from_last_transaction': np.abs(np.random.normal(3, 5, n_legit)),\n",
    "        'transaction_velocity': np.random.poisson(2, n_legit),\n",
    "        'is_fraud': np.zeros(n_legit, dtype=int)\n",
    "    }\n",
    "    \n",
    "    # Fraudulent transactions (different patterns)\n",
    "    fraud_data = {\n",
    "        'transaction_amount': np.random.gamma(5, 100, n_fraud),  # Higher amounts\n",
    "        'hour_of_day': np.random.choice(range(24), n_fraud, p=fraud_hour_probs),  # More at night\n",
    "        'day_of_week': np.random.randint(0, 7, n_fraud),\n",
    "        'merchant_category': np.random.choice(\n",
    "            ['retail', 'grocery', 'gas', 'restaurant', 'online'],\n",
    "            n_fraud,\n",
    "            p=[0.15, 0.10, 0.15, 0.10, 0.50]  # More online\n",
    "        ),\n",
    "        'distance_from_home': np.abs(np.random.normal(50, 100, n_fraud)),  # Farther\n",
    "        'distance_from_last_transaction': np.abs(np.random.normal(100, 200, n_fraud)),\n",
    "        'transaction_velocity': np.random.poisson(8, n_fraud),  # Higher velocity\n",
    "        'is_fraud': np.ones(n_fraud, dtype=int)\n",
    "    }\n",
    "    \n",
    "    # Combine and shuffle\n",
    "    df_legit = pd.DataFrame(legit_data)\n",
    "    df_fraud = pd.DataFrame(fraud_data)\n",
    "    df = pd.concat([df_legit, df_fraud], ignore_index=True)\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate dataset\n",
    "df = generate_fraud_dataset(n_samples=100000, fraud_ratio=0.02)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df['is_fraud'].value_counts())\n",
    "print(\"\\nFraud ratio:\", df['is_fraud'].mean())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìà Partie 2: Exploration Visuelle des Donn√©es\n",
    "\n",
    "### Objectif de l'Exploration\n",
    "\n",
    "Avant de mod√©liser, nous devons **comprendre** les donn√©es :\n",
    "- ‚úÖ Identifier les **diff√©rences** entre transactions l√©gitimes et frauduleuses\n",
    "- ‚úÖ D√©tecter des **patterns** exploitables par le ML\n",
    "- ‚úÖ V√©rifier qu'il n'y a pas de **data leakage**\n",
    "- ‚úÖ Confirmer le **d√©s√©quilibre** des classes\n",
    "\n",
    "### Questions √† R√©pondre\n",
    "\n",
    "1. **Montant** : Les fraudes sont-elles plus ch√®res ?\n",
    "2. **Temps** : Y a-t-il des heures √† risque ?\n",
    "3. **Distance** : Les fraudes se produisent-elles loin du domicile ?\n",
    "4. **V√©locit√©** : Les fraudeurs font-ils plus de transactions rapidement ?\n",
    "\n",
    "Regardons les visualisations ci-dessous üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Transaction amount\n",
    "axes[0, 0].hist(df[df['is_fraud']==0]['transaction_amount'], bins=50, alpha=0.5, label='Legit')\n",
    "axes[0, 0].hist(df[df['is_fraud']==1]['transaction_amount'], bins=50, alpha=0.5, label='Fraud')\n",
    "axes[0, 0].set_xlabel('Transaction Amount')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_title('Transaction Amount Distribution')\n",
    "\n",
    "# Hour of day\n",
    "df.groupby(['hour_of_day', 'is_fraud']).size().unstack().plot(ax=axes[0, 1])\n",
    "axes[0, 1].set_xlabel('Hour of Day')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].set_title('Transactions by Hour')\n",
    "\n",
    "# Distance from home\n",
    "axes[1, 0].hist(df[df['is_fraud']==0]['distance_from_home'], bins=50, alpha=0.5, label='Legit')\n",
    "axes[1, 0].hist(df[df['is_fraud']==1]['distance_from_home'], bins=50, alpha=0.5, label='Fraud')\n",
    "axes[1, 0].set_xlabel('Distance from Home')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].set_title('Distance from Home Distribution')\n",
    "\n",
    "# Transaction velocity\n",
    "axes[1, 1].hist(df[df['is_fraud']==0]['transaction_velocity'], bins=20, alpha=0.5, label='Legit')\n",
    "axes[1, 1].hist(df[df['is_fraud']==1]['transaction_velocity'], bins=20, alpha=0.5, label='Fraud')\n",
    "axes[1, 1].set_xlabel('Transaction Velocity')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_title('Transaction Velocity Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üî® Partie 3: Feature Engineering\n",
    "\n",
    "### Qu'est-ce que le Feature Engineering ?\n",
    "\n",
    "Le **Feature Engineering** est l'art de cr√©er de nouvelles variables √† partir des donn√©es brutes pour am√©liorer la performance du mod√®le.\n",
    "\n",
    "### Nouvelles Features Cr√©√©es\n",
    "\n",
    "| Feature | Formule | Intuition |\n",
    "|---------|---------|-----------|\n",
    "| `is_weekend` | day_of_week >= 5 | Comportement diff√©rent le weekend |\n",
    "| `is_night` | (hour >= 22) OR (hour <= 6) | Fraudes plus fr√©quentes la nuit |\n",
    "| `amount_velocity_ratio` | amount / velocity | Montant par transaction |\n",
    "| `distance_ratio` | distance_last / distance_home | Ratio de distances |\n",
    "\n",
    "### Pourquoi ces Features ?\n",
    "\n",
    "**Exemple** : `is_night`\n",
    "- üåô Les transactions la nuit (22h-6h) sont **plus suspectes**\n",
    "- üë§ La plupart des gens dorment ‚Üí activit√© anormale\n",
    "- ü§ñ Le mod√®le peut apprendre ce pattern facilement\n",
    "\n",
    "**Exemple** : `amount_velocity_ratio`\n",
    "- üí∞ Si quelqu'un fait 10 transactions de $1000 rapidement ‚Üí suspect\n",
    "- üìä Capture la **relation** entre deux variables\n",
    "- üéØ Plus informatif que les variables s√©par√©ment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional features\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "df['is_night'] = ((df['hour_of_day'] >= 22) | (df['hour_of_day'] <= 6)).astype(int)\n",
    "df['amount_velocity_ratio'] = df['transaction_amount'] / (df['transaction_velocity'] + 1)\n",
    "df['distance_ratio'] = df['distance_from_last_transaction'] / (df['distance_from_home'] + 1)\n",
    "\n",
    "# Encode categorical variable\n",
    "le = LabelEncoder()\n",
    "df['merchant_category_encoded'] = le.fit_transform(df['merchant_category'])\n",
    "\n",
    "print(\"Engineered features:\")\n",
    "df[['is_weekend', 'is_night', 'amount_velocity_ratio', 'distance_ratio', 'merchant_category_encoded']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üé≤ Partie 4: Pr√©paration des Donn√©es pour le Modeling\n",
    "\n",
    "### Train / Validation / Test Split\n",
    "\n",
    "Nous divisons les donn√©es en **3 sets** :\n",
    "\n",
    "```\n",
    "Dataset (100%)\n",
    "‚îú‚îÄ‚îÄ Train (60%)      ‚Üí Entra√Ænement du mod√®le\n",
    "‚îú‚îÄ‚îÄ Validation (20%) ‚Üí Tuning des hyperparam√®tres\n",
    "‚îî‚îÄ‚îÄ Test (20%)       ‚Üí √âvaluation finale (jamais vu pendant training)\n",
    "```\n",
    "\n",
    "### Pourquoi 3 Splits ?\n",
    "\n",
    "**Probl√®me avec 2 splits** (Train/Test uniquement) :\n",
    "- ‚ùå Risque d'**overfitting** sur le test set\n",
    "- ‚ùå Pas de set ind√©pendant pour tuning\n",
    "\n",
    "**Solution avec 3 splits** :\n",
    "1. **Train** : Entra√Æner le mod√®le\n",
    "2. **Validation** : Optimiser les hyperparam√®tres\n",
    "3. **Test** : √âvaluation finale **non biais√©e**\n",
    "\n",
    "### Stratification\n",
    "\n",
    "`stratify=y` assure que chaque split a le **m√™me ratio** de fraude (2%) :\n",
    "```\n",
    "Train:      98% legit, 2% fraud\n",
    "Validation: 98% legit, 2% fraud  \n",
    "Test:       98% legit, 2% fraud\n",
    "```\n",
    "\n",
    "Sans stratification, on pourrait avoir 0% de fraude dans un split ! üò±\n",
    "\n",
    "### Feature Scaling\n",
    "\n",
    "**StandardScaler** : $(x - \\mu) / \\sigma$\n",
    "\n",
    "**Pourquoi ?**\n",
    "- Features ont des √©chelles diff√©rentes (amount: 0-1000, hour: 0-23)\n",
    "- Certains algorithmes (Logistic Regression, SVM) sont sensibles √† l'√©chelle\n",
    "- Tree-based models (XGBoost) ne sont pas affect√©s, mais √ßa ne fait pas de mal\n",
    "\n",
    "‚ö†Ô∏è **Important** : Fit sur train, transform sur val/test (√©viter data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "feature_cols = [\n",
    "    'transaction_amount', 'hour_of_day', 'day_of_week',\n",
    "    'distance_from_home', 'distance_from_last_transaction',\n",
    "    'transaction_velocity', 'is_weekend', 'is_night',\n",
    "    'amount_velocity_ratio', 'distance_ratio', 'merchant_category_encoded'\n",
    "]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['is_fraud']\n",
    "\n",
    "# Split data: 60% train, 20% validation, 20% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape}, Fraud ratio: {y_train.mean():.4f}\")\n",
    "print(f\"Validation set: {X_val.shape}, Fraud ratio: {y_val.mean():.4f}\")\n",
    "print(f\"Test set: {X_test.shape}, Fraud ratio: {y_test.mean():.4f}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Handle Imbalanced Data with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚öñÔ∏è Partie 5: G√©rer le D√©s√©quilibre avec SMOTE\n",
    "\n",
    "### Le Probl√®me du D√©s√©quilibre\n",
    "\n",
    "Avec seulement 2% de fraudes, le mod√®le peut facilement apprendre √† **toujours pr√©dire \"normal\"** :\n",
    "\n",
    "```\n",
    "Accuracy = 98% (en pr√©disant toujours 0)\n",
    "Mais Recall = 0% (aucune fraude d√©tect√©e!) ‚ùå\n",
    "```\n",
    "\n",
    "### Qu'est-ce que SMOTE ?\n",
    "\n",
    "**SMOTE** = Synthetic Minority Over-sampling Technique\n",
    "\n",
    "**Comment √ßa marche ?**\n",
    "1. Prendre un exemple de fraude (minorit√©)\n",
    "2. Trouver ses k voisins les plus proches (aussi des fraudes)\n",
    "3. Cr√©er un **nouvel exemple synth√©tique** entre les deux\n",
    "\n",
    "```\n",
    "Fraude A : [100, 50, 20]\n",
    "Fraude B : [120, 60, 25]\n",
    "         ‚Üì SMOTE ‚Üì\n",
    "Nouvelle : [110, 55, 22.5] (moyenne interpol√©e)\n",
    "```\n",
    "\n",
    "### Alternatives √† SMOTE\n",
    "\n",
    "| Technique | Approche | Avantages | Inconv√©nients |\n",
    "|-----------|----------|-----------|---------------|\n",
    "| **SMOTE** | Over-sampling (cr√©er exemples) | ‚úÖ Pas de perte d'info | ‚ö†Ô∏è Peut cr√©er du bruit |\n",
    "| **Undersampling** | Supprimer exemples majoritaires | ‚úÖ Plus rapide | ‚ùå Perte d'information |\n",
    "| **Class Weights** | P√©naliser erreurs sur minorit√© | ‚úÖ Pas de modification data | ‚ö†Ô∏è Sensible au tuning |\n",
    "| **Ensemble** | Combiner plusieurs mod√®les | ‚úÖ Performance | ‚ùå Plus complexe |\n",
    "\n",
    "### Pourquoi SMOTE sur Train Seulement ?\n",
    "\n",
    "‚ö†Ô∏è **Critique** : On applique SMOTE **uniquement** sur le training set\n",
    "\n",
    "**Raison** :\n",
    "- Validation et Test doivent refl√©ter la **distribution r√©elle** (98%/2%)\n",
    "- Sinon, on surestime la performance en production\n",
    "- Le mod√®le doit apprendre √† g√©rer le d√©s√©quilibre\n",
    "\n",
    "```python\n",
    "# ‚úÖ BON\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "model.evaluate(X_val, y_val)  # Val garde le d√©s√©quilibre\n",
    "\n",
    "# ‚ùå MAUVAIS\n",
    "X_val_balanced, y_val_balanced = smote.fit_resample(X_val, y_val)\n",
    "model.evaluate(X_val_balanced, y_val_balanced)  # Performance irr√©aliste!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Original training set: {X_train_scaled.shape}\")\n",
    "print(f\"Balanced training set: {X_train_balanced.shape}\")\n",
    "print(f\"\\nOriginal fraud ratio: {y_train.mean():.4f}\")\n",
    "print(f\"Balanced fraud ratio: {y_train_balanced.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü§ñ Partie 6: Entra√Ænement de Mod√®les\n",
    "\n",
    "### Pourquoi 3 Mod√®les ?\n",
    "\n",
    "Nous entra√Ænons **3 algorithmes diff√©rents** pour comparer :\n",
    "\n",
    "#### 1. Logistic Regression (Baseline)\n",
    "```\n",
    "‚úÖ Simple et interpr√©table\n",
    "‚úÖ Rapide √† entra√Æner\n",
    "‚ùå Assume relations lin√©aires\n",
    "‚ùå Moins performant sur donn√©es complexes\n",
    "```\n",
    "\n",
    "**Quand l'utiliser ?**\n",
    "- Baseline simple\n",
    "- Besoin d'interpr√©tabilit√© (coefficients)\n",
    "- Peu de features\n",
    "\n",
    "#### 2. XGBoost\n",
    "```\n",
    "‚úÖ √âtat de l'art sur donn√©es tabulaires\n",
    "‚úÖ G√®re les non-lin√©arit√©s\n",
    "‚úÖ Feature importance built-in\n",
    "‚ùå Plus lent √† entra√Æner\n",
    "‚ùå Plus de hyperparam√®tres √† tuner\n",
    "```\n",
    "\n",
    "**Quand l'utiliser ?**\n",
    "- Performance maximale\n",
    "- Donn√©es tabulaires\n",
    "- Accepte la complexit√©\n",
    "\n",
    "#### 3. LightGBM\n",
    "```\n",
    "‚úÖ Plus rapide que XGBoost\n",
    "‚úÖ Moins de m√©moire\n",
    "‚úÖ Bon sur gros datasets\n",
    "‚ùå Peut overfitter sur petits datasets\n",
    "```\n",
    "\n",
    "**Quand l'utiliser ?**\n",
    "- Gros datasets (> 10K exemples)\n",
    "- Contraintes de temps/m√©moire\n",
    "- Production √† haute fr√©quence\n",
    "\n",
    "### Hyperparam√®tres Cl√©s\n",
    "\n",
    "| Param√®tre | XGBoost / LightGBM | Effet |\n",
    "|-----------|-------------------|-------|\n",
    "| `n_estimators` | 100 | Nombre d'arbres (‚Üë = mieux, mais overfitting) |\n",
    "| `max_depth` | 6 | Profondeur des arbres (‚Üë = plus complexe) |\n",
    "| `learning_rate` | 0.1 | Taux d'apprentissage (‚Üì = plus pr√©cis, mais lent) |\n",
    "\n",
    "**R√®gle g√©n√©rale** : Plus de `n_estimators` + plus petit `learning_rate` = meilleure performance (mais plus lent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression (baseline)\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='auc'\n",
    ")\n",
    "xgb_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Train LightGBM\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "lgb_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "print(\"All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Partie 7: √âvaluation des Mod√®les\n",
    "\n",
    "### M√©triques pour Classes D√©s√©quilibr√©es\n",
    "\n",
    "‚ùå **Accuracy** : Pas adapt√©e ! (99% en pr√©disant toujours \"normal\")\n",
    "\n",
    "‚úÖ **M√©triques √† utiliser** :\n",
    "\n",
    "#### 1. Precision (Pr√©cision)\n",
    "```\n",
    "Precision = TP / (TP + FP)\n",
    "```\n",
    "**Question** : Parmi les transactions flagg√©es comme fraude, combien le sont vraiment ?\n",
    "\n",
    "**Business impact** : Co√ªt d'investigation des faux positifs\n",
    "\n",
    "#### 2. Recall (Rappel / Sensibilit√©)\n",
    "```\n",
    "Recall = TP / (TP + FN)\n",
    "```\n",
    "**Question** : Parmi toutes les fraudes r√©elles, combien avons-nous d√©tect√©es ?\n",
    "\n",
    "**Business impact** : Fraudes manqu√©es = pertes financi√®res\n",
    "\n",
    "#### 3. F1-Score\n",
    "```\n",
    "F1 = 2 √ó (Precision √ó Recall) / (Precision + Recall)\n",
    "```\n",
    "**Question** : Quelle est la moyenne harmonique entre Precision et Recall ?\n",
    "\n",
    "**Usage** : √âquilibrer les deux m√©triques\n",
    "\n",
    "#### 4. ROC-AUC\n",
    "```\n",
    "AUC = Area Under the ROC Curve\n",
    "```\n",
    "**Question** : Quelle est la capacit√© du mod√®le √† discriminer entre classes ?\n",
    "\n",
    "**Interpr√©tation** :\n",
    "- 1.0 = Parfait (s√©pare parfaitement)\n",
    "- 0.5 = Random (comme lancer une pi√®ce)\n",
    "- < 0.5 = Pire que random (mod√®le invers√© ?)\n",
    "\n",
    "### Confusion Matrix\n",
    "\n",
    "```\n",
    "                Predicted\n",
    "              Neg    Pos\n",
    "Actual Neg    TN     FP   ‚Üê False Positive = Co√ªt investigation\n",
    "       Pos    FN     TP   ‚Üê False Negative = Fraude manqu√©e $$$$\n",
    "```\n",
    "\n",
    "**Objectif Business** : Minimiser FN (fraudes manqu√©es) tout en gardant FP raisonnable\n",
    "\n",
    "### Trade-off Precision vs Recall\n",
    "\n",
    "```\n",
    "Seuil = 0.5 (d√©faut)\n",
    "Precision = 85%, Recall = 70%\n",
    "\n",
    "Seuil = 0.3 (plus sensible)\n",
    "Precision = 60%, Recall = 90%  ‚Üê D√©tecte plus de fraudes, mais plus de faux positifs\n",
    "\n",
    "Seuil = 0.7 (plus conservateur)\n",
    "Precision = 95%, Recall = 50%  ‚Üê Moins de faux positifs, mais manque des fraudes\n",
    "```\n",
    "\n",
    "**Choisir le seuil** selon le business :\n",
    "- **Banque** : Recall √©lev√© (ne pas manquer de fraudes) ‚Üí seuil bas (0.3)\n",
    "- **E-commerce** : Precision √©lev√©e (ne pas bloquer clients l√©gitimes) ‚Üí seuil haut (0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "models = {\n",
    "    'Logistic Regression': lr_model,\n",
    "    'XGBoost': xgb_model,\n",
    "    'LightGBM': lgb_model\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    y_pred_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    \n",
    "    results[name] = {\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba,\n",
    "        'roc_auc': roc_auc\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "for name, result in results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_val, result['probabilities'])\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC = {result['roc_auc']:.4f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Precision-Recall curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "for name, result in results.items():\n",
    "    precision, recall, _ = precision_recall_curve(y_val, result['probabilities'])\n",
    "    plt.plot(recall, precision, label=name)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost-sensitive evaluation\n",
    "cost_fp = 5   # Cost of investigating a legitimate transaction\n",
    "cost_fn = 100  # Cost of missing a fraudulent transaction\n",
    "\n",
    "print(\"Cost-Sensitive Evaluation:\")\n",
    "print(\"=\"*50)\n",
    "for name, result in results.items():\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, result['predictions']).ravel()\n",
    "    total_cost = (fp * cost_fp) + (fn * cost_fn)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  False Positives: {fp}, Cost: ${fp * cost_fp}\")\n",
    "    print(f\"  False Negatives: {fn}, Cost: ${fn * cost_fn}\")\n",
    "    print(f\"  Total Cost: ${total_cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate best model on test set\n",
    "y_test_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "y_test_pred = (y_test_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"Final Test Set Performance:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_test_pred_proba):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and preprocessing artifacts\n",
    "import os\n",
    "\n",
    "model_dir = '../../models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(best_model, f'{model_dir}/fraud_detection_model.pkl')\n",
    "joblib.dump(scaler, f'{model_dir}/fraud_detection_scaler.pkl')\n",
    "joblib.dump(le, f'{model_dir}/fraud_detection_encoder.pkl')\n",
    "joblib.dump(feature_cols, f'{model_dir}/fraud_detection_features.pkl')\n",
    "\n",
    "print(\"Model artifacts saved successfully!\")\n",
    "print(f\"Location: {model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate final metrics on test set\n",
    "y_test_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "y_test_pred = (y_test_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "final_metrics = {\n",
    "    \"accuracy\": float(accuracy_score(y_test, y_test_pred)),\n",
    "    \"precision\": float(precision_score(y_test, y_test_pred)),\n",
    "    \"recall\": float(recall_score(y_test, y_test_pred)),\n",
    "    \"f1\": float(f1_score(y_test, y_test_pred)),\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, y_test_pred_proba))\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Final Test Metrics:\")\n",
    "for key, value in final_metrics.items():\n",
    "    print(f\"   {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. SageMaker Integration: Training Job & Experiments\n",
    "\n",
    "Dans cette section, nous allons utiliser les services natifs de SageMaker :\n",
    "- **SageMaker Training Jobs** : Entra√Ænement scalable et reproductible\n",
    "- **SageMaker Experiments** : Tracking automatique des hyperparam√®tres et m√©triques\n",
    "- **SageMaker Model Registry** : Versioning et gestion du cycle de vie des mod√®les\n",
    "\n",
    "### Pourquoi SageMaker Training Jobs ?\n",
    "\n",
    "‚úÖ **Scalabilit√©** : Choisissez la taille d'instance adapt√©e  \n",
    "‚úÖ **Reproductibilit√©** : Environnement containeris√©  \n",
    "‚úÖ **Tracking automatique** : Int√©gration avec SageMaker Experiments  \n",
    "‚úÖ **Co√ªt optimis√©** : Payez uniquement pour le temps d'entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup SageMaker\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn import SKLearn\n",
    "from sagemaker.experiments import Run\n",
    "import boto3\n",
    "\n",
    "# Initialize SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(f\"‚úÖ SageMaker Session initialized\")\n",
    "print(f\"   Region: {region}\")\n",
    "print(f\"   Bucket: {bucket}\")\n",
    "print(f\"   Role: {role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload training data to S3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare data for SageMaker\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "val_data = pd.concat([X_val, y_val], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Save to CSV\n",
    "os.makedirs('data', exist_ok=True)\n",
    "train_data.to_csv('data/train.csv', index=False, header=False)\n",
    "val_data.to_csv('data/validation.csv', index=False, header=False)\n",
    "test_data.to_csv('data/test.csv', index=False, header=False)\n",
    "\n",
    "# Upload to S3\n",
    "s3_prefix = 'fraud-detection-lab1'\n",
    "s3_train = sagemaker_session.upload_data(\n",
    "    path='data/train.csv',\n",
    "    bucket=bucket,\n",
    "    key_prefix=f'{s3_prefix}/data'\n",
    ")\n",
    "s3_validation = sagemaker_session.upload_data(\n",
    "    path='data/validation.csv',\n",
    "    bucket=bucket,\n",
    "    key_prefix=f'{s3_prefix}/data'\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data uploaded to S3:\")\n",
    "print(f\"   Training: {s3_train}\")\n",
    "print(f\"   Validation: {s3_validation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Create Training Script\n",
    "\n",
    "Pour SageMaker Training, nous cr√©ons un script Python autonome qui sera ex√©cut√© dans un container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "imbalanced-learn==0.12.3\n",
    "xgboost==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚úÖ Requirements file created: requirements.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile fraud_train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Hyperparameters\n",
    "    parser.add_argument('--n-estimators', type=int, default=100)\n",
    "    parser.add_argument('--max-depth', type=int, default=6)\n",
    "    parser.add_argument('--learning-rate', type=float, default=0.1)\n",
    "    parser.add_argument('--threshold', type=float, default=0.5)\n",
    "    \n",
    "    # SageMaker specific arguments\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAINING'))\n",
    "    parser.add_argument('--validation', type=str, default=os.environ.get('SM_CHANNEL_VALIDATION'))\n",
    "    parser.add_argument('--output-data-dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    print(f\"Model dir: {args.model_dir}\")\n",
    "    print(f\"Train dir: {args.train}\")\n",
    "    print(f\"Validation dir: {args.validation}\")\n",
    "    \n",
    "    # Import here to avoid issues if not available\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    import xgboost as xgb\n",
    "    \n",
    "    # Load data\n",
    "    print(\"Loading training data...\")\n",
    "    train_df = pd.read_csv(os.path.join(args.train, 'train.csv'), header=None)\n",
    "    val_df = pd.read_csv(os.path.join(args.validation, 'validation.csv'), header=None)\n",
    "    \n",
    "    print(f\"Train shape: {train_df.shape}\")\n",
    "    print(f\"Validation shape: {val_df.shape}\")\n",
    "    \n",
    "    # Split features and target\n",
    "    X_train = train_df.iloc[:, :-1]\n",
    "    y_train = train_df.iloc[:, -1]\n",
    "    X_val = val_df.iloc[:, :-1]\n",
    "    y_val = val_df.iloc[:, -1]\n",
    "    \n",
    "    # Apply SMOTE\n",
    "    print(f\"Original training set: {X_train.shape}\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "    print(f\"Balanced training set: {X_train_balanced.shape}\")\n",
    "    \n",
    "    # Calculate scale_pos_weight\n",
    "    neg_count = len(y_train[y_train==0])\n",
    "    pos_count = len(y_train[y_train==1])\n",
    "    scale_pos_weight = neg_count / pos_count if pos_count > 0 else 1.0\n",
    "    \n",
    "    # Train XGBoost model\n",
    "    print(\"Training XGBoost model...\")\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=args.n_estimators,\n",
    "        max_depth=args.max_depth,\n",
    "        learning_rate=args.learning_rate,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        eval_metric='logloss',\n",
    "        random_state=42,\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train_balanced, y_train_balanced,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    y_val_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    y_val_pred = (y_val_pred_proba >= args.threshold).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'accuracy': float(accuracy_score(y_val, y_val_pred)),\n",
    "        'precision': float(precision_score(y_val, y_val_pred, zero_division=0)),\n",
    "        'recall': float(recall_score(y_val, y_val_pred, zero_division=0)),\n",
    "        'f1': float(f1_score(y_val, y_val_pred, zero_division=0)),\n",
    "        'roc_auc': float(roc_auc_score(y_val, y_val_pred_proba))\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nValidation Metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    model_path = os.path.join(args.model_dir, 'xgboost-model')\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"\\nModel saved to: {model_path}\")\n",
    "    \n",
    "    # Save metrics\n",
    "    if args.output_data_dir:\n",
    "        metrics_path = os.path.join(args.output_data_dir, 'metrics.json')\n",
    "        os.makedirs(args.output_data_dir, exist_ok=True)\n",
    "        with open(metrics_path, 'w') as f:\n",
    "            json.dump(metrics, f)\n",
    "        print(f\"Metrics saved to: {metrics_path}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Training completed successfully!\")\n",
    "\n",
    "print(\"‚úÖ Training script created: fraud_train.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ Launch SageMaker Training Job with Experiments Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "from sagemaker.experiments.run import Run\n",
    "import time\n",
    "\n",
    "# Define experiment and run names\n",
    "experiment_name = \"fraud-detection-experiment\"\n",
    "run_name = f\"xgboost-run-{int(time.time())}\"\n",
    "\n",
    "# Hyperparameters to test\n",
    "hyperparameters = {\n",
    "    'n-estimators': 100,\n",
    "    'max-depth': 6,\n",
    "    'learning-rate': 0.1,\n",
    "    'threshold': 0.5\n",
    "}\n",
    "\n",
    "# Create SageMaker Estimator with dependencies\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='fraud_train.py',\n",
    "    role=role,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    instance_count=1,\n",
    "    framework_version='1.2-1',\n",
    "    py_version='py3',\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=f's3://{bucket}/{s3_prefix}/output',\n",
    "    code_location=f's3://{bucket}/{s3_prefix}/code',\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    dependencies=['requirements.txt']  # Install additional packages\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Estimator configured\")\n",
    "print(f\"   Instance type: ml.m5.xlarge\")\n",
    "print(f\"   Framework: scikit-learn 1.2-1\")\n",
    "print(f\"   Dependencies: requirements.txt (imbalanced-learn, xgboost)\")\n",
    "print(f\"\\nüéØ Starting training with SageMaker Experiments...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch training with Experiments tracking\n",
    "with Run(\n",
    "    experiment_name=experiment_name,\n",
    "    run_name=run_name,\n",
    "    sagemaker_session=sagemaker_session\n",
    ") as run:\n",
    "    \n",
    "    # Log hyperparameters\n",
    "    run.log_parameters(hyperparameters)\n",
    "    \n",
    "    # Start training\n",
    "    sklearn_estimator.fit({\n",
    "        'training': s3_train,\n",
    "        'validation': s3_validation\n",
    "    }, wait=True)\n",
    "    \n",
    "    # Log model artifact location\n",
    "    run.log_file(sklearn_estimator.model_data, name=\"model_artifact\", is_output=True)\n",
    "    \n",
    "    print(f\"\\\\n‚úÖ Training completed!\")\n",
    "    print(f\"   Experiment: {experiment_name}\")\n",
    "    print(f\"   Run: {run_name}\")\n",
    "    print(f\"   Model artifact: {sklearn_estimator.model_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì¶ Register Model in SageMaker Model Registry\n",
    "\n",
    "Le Model Registry permet de :\n",
    "- Versionner vos mod√®les\n",
    "- Approuver/rejeter des versions\n",
    "- Suivre le cycle de vie (Dev ‚Üí Staging ‚Üí Production)\n",
    "- Int√©grer avec des pipelines CI/CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.sklearn import SKLearnModel\n",
    "\n",
    "# Create model package group (registry)\n",
    "model_package_group_name = \"fraud-detection-models\"\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "try:\n",
    "    sm_client.create_model_package_group(\n",
    "        ModelPackageGroupName=model_package_group_name,\n",
    "        ModelPackageGroupDescription=\"Fraud detection models for production\"\n",
    "    )\n",
    "    print(f\"‚úÖ Created Model Package Group: {model_package_group_name}\")\n",
    "except sm_client.exceptions.ResourceInUse:\n",
    "    print(f\"‚ÑπÔ∏è  Model Package Group already exists: {model_package_group_name}\")\n",
    "\n",
    "# Register the trained model\n",
    "model = SKLearnModel(\n",
    "    model_data=sklearn_estimator.model_data,\n",
    "    role=role,\n",
    "    entry_point='fraud_train.py',\n",
    "    framework_version='1.2-1',\n",
    "    py_version='py3',\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Register model in Model Registry\n",
    "model_package = model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=\"PendingManualApproval\",\n",
    "    description=\"XGBoost fraud detection model trained with SMOTE\"\n",
    ")\n",
    "\n",
    "print(f\"\\\\n‚úÖ Model registered in Model Registry!\")\n",
    "print(f\"   Model Package ARN: {model_package.model_package_arn}\")\n",
    "print(f\"   Approval Status: PendingManualApproval\")\n",
    "print(f\"\\\\nüí° To approve: SageMaker Console ‚Üí Model Registry ‚Üí {model_package_group_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç View Experiment Results\n",
    "\n",
    "Visualisons les r√©sultats de notre exp√©rience SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "# Get experiment results\n",
    "experiment_analytics = ExperimentAnalytics(\n",
    "    experiment_name=experiment_name,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Display results as DataFrame\n",
    "results_df = experiment_analytics.dataframe()\n",
    "\n",
    "if not results_df.empty:\n",
    "    print(\"üìä Experiment Results:\")\n",
    "    print(results_df[['TrialComponentName', 'n_estimators', 'max_depth', 'learning_rate']].head())\n",
    "    print(f\"\\\\n‚úÖ Total runs: {len(results_df)}\")\n",
    "    print(f\"\\\\nüí° View full results in SageMaker Studio:\")\n",
    "    print(f\"   Experiments & Trials ‚Üí {experiment_name}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No results yet. Training may still be in progress.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Class Imbalance**: SMOTE significantly improved model performance\n",
    "2. **Model Selection**: XGBoost/LightGBM outperformed logistic regression\n",
    "3. **Feature Engineering**: Temporal and distance-based features were crucial\n",
    "4. **SageMaker Training**: Scalable and reproducible training with managed infrastructure\n",
    "5. **Experiments Tracking**: Automatic logging of hyperparameters and metrics\n",
    "6. **Model Registry**: Centralized model versioning and approval workflow\n",
    "\n",
    "## Next Steps for Production\n",
    "\n",
    "1. **Deploy** from Model Registry to real-time endpoint\n",
    "2. Set up **Model Monitor** for data drift detection\n",
    "3. Implement **SageMaker Pipelines** for automated retraining\n",
    "4. Add **Feature Store** for real-time features\n",
    "5. Set up **A/B testing** with production traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßπ Cleanup Resources\n",
    "\n",
    "Nettoyez les ressources AWS pour √©viter les co√ªts inutiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cleanup AWS Resources\n",
    "# ============================================================\n",
    "\n",
    "import boto3\n",
    "\n",
    "print(\"üßπ Cleaning up Lab 1 resources...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "# List all resources created in this lab\n",
    "resources_deleted = []\n",
    "\n",
    "try:\n",
    "    # 1. List and optionally delete Training Jobs (they stop automatically, but you can view them)\n",
    "    print(\"\\nüìã Training Jobs:\")\n",
    "    training_jobs = sm_client.list_training_jobs(\n",
    "        NameContains='fraud-detection',\n",
    "        MaxResults=10,\n",
    "        SortBy='CreationTime',\n",
    "        SortOrder='Descending'\n",
    "    )\n",
    "    \n",
    "    for job in training_jobs['TrainingJobSummaries']:\n",
    "        print(f\"  ‚Ä¢ {job['TrainingJobName']} - Status: {job['TrainingJobStatus']}\")\n",
    "    \n",
    "    if training_jobs['TrainingJobSummaries']:\n",
    "        print(\"  üí° Training jobs are automatically stopped and don't incur costs\")\n",
    "    else:\n",
    "        print(\"  ‚úÖ No training jobs found\")\n",
    "    \n",
    "    # 2. List Model Packages in Registry\n",
    "    print(\"\\nüì¶ Model Registry:\")\n",
    "    try:\n",
    "        model_packages = sm_client.list_model_packages(\n",
    "            ModelPackageGroupName='fraud-detection-model-group',\n",
    "            MaxResults=10\n",
    "        )\n",
    "        \n",
    "        for pkg in model_packages['ModelPackageSummaryList']:\n",
    "            print(f\"  ‚Ä¢ Version {pkg.get('ModelPackageVersion', 'N/A')} - Status: {pkg['ModelApprovalStatus']}\")\n",
    "        \n",
    "        print(\"\\n  üí° To delete model packages (optional):\")\n",
    "        print(\"  # for pkg in model_packages['ModelPackageSummaryList']:\")\n",
    "        print(\"  #     sm_client.delete_model_package(ModelPackageName=pkg['ModelPackageArn'])\")\n",
    "        \n",
    "    except sm_client.exceptions.ResourceNotFound:\n",
    "        print(\"  ‚úÖ No model package group found\")\n",
    "    \n",
    "    # 3. List Experiments\n",
    "    print(\"\\nüî¨ Experiments:\")\n",
    "    try:\n",
    "        experiments = sm_client.list_experiments(\n",
    "            MaxResults=10\n",
    "        )\n",
    "        \n",
    "        fraud_experiments = [e for e in experiments['ExperimentSummaries'] \n",
    "                            if 'fraud' in e['ExperimentName'].lower()]\n",
    "        \n",
    "        if fraud_experiments:\n",
    "            for exp in fraud_experiments:\n",
    "                print(f\"  ‚Ä¢ {exp['ExperimentName']}\")\n",
    "            print(\"\\n  üí° Experiments don't incur costs and provide history\")\n",
    "        else:\n",
    "            print(\"  ‚úÖ No fraud detection experiments found\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Note: {e}\")\n",
    "    \n",
    "    # 4. Check for any deployed endpoints (shouldn't exist in this lab)\n",
    "    print(\"\\nüîå Endpoints:\")\n",
    "    endpoints = sm_client.list_endpoints(\n",
    "        NameContains='fraud',\n",
    "        StatusEquals='InService'\n",
    "    )\n",
    "    \n",
    "    if endpoints['Endpoints']:\n",
    "        print(f\"  ‚ö†Ô∏è  Found {len(endpoints['Endpoints'])} endpoint(s):\")\n",
    "        for ep in endpoints['Endpoints']:\n",
    "            print(f\"    ‚Ä¢ {ep['EndpointName']}\")\n",
    "        \n",
    "        # Uncomment to delete endpoints\n",
    "        # for ep in endpoints['Endpoints']:\n",
    "        #     sm_client.delete_endpoint(EndpointName=ep['EndpointName'])\n",
    "        #     print(f\"    ‚úÖ Deleted: {ep['EndpointName']}\")\n",
    "        #     resources_deleted.append(ep['EndpointName'])\n",
    "    else:\n",
    "        print(\"  ‚úÖ No endpoints found (good - Lab 1 doesn't deploy endpoints)\")\n",
    "    \n",
    "    # 5. S3 Data (optional - you may want to keep training data)\n",
    "    print(\"\\nüíæ S3 Data:\")\n",
    "    print(f\"  Data location: s3://{bucket}/lab1-fraud-detection/\")\n",
    "    print(\"  üí° Training data and models are stored here\")\n",
    "    print(\"  üí° You can delete manually if needed:\")\n",
    "    print(f\"  # aws s3 rm s3://{bucket}/lab1-fraud-detection/ --recursive\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ Cleanup check complete!\")\n",
    "    print(\"\\nüí∞ Cost Impact:\")\n",
    "    print(\"  ‚Ä¢ Training Jobs: ‚úÖ Stopped automatically (no ongoing cost)\")\n",
    "    print(\"  ‚Ä¢ Model Registry: ‚úÖ No cost for storing model metadata\")\n",
    "    print(\"  ‚Ä¢ Experiments: ‚úÖ No cost\")\n",
    "    print(\"  ‚Ä¢ S3 Storage: üí≤ Minimal cost (~few cents)\")\n",
    "    print(\"  ‚Ä¢ Endpoints: ‚úÖ None deployed\")\n",
    "    \n",
    "    if resources_deleted:\n",
    "        print(f\"\\nüóëÔ∏è  Deleted resources: {', '.join(resources_deleted)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during cleanup: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
