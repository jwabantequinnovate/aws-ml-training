# AWS ML Training - 2-Day MLOps Workshop

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Poetry](https://img.shields.io/badge/dependency%20manager-poetry-blue)](https://python-poetry.org/)

2-day hands-on training covering AWS SageMaker and production MLOps patterns.

## ğŸ¯ Overview

This workshop provides practical experience with AWS machine learning services through 9 comprehensive labs. You'll build real ML systems handling fraud detection, customer churn, text classification, and generative AI.

## ğŸ“š Workshop Structure (2 Days)

### Day 1: ML Fundamentals + MLOps Tools

| Lab | Topic | Duration | Key Skills |
|-----|-------|----------|------------|
| **Lab 1** | Fraud Detection | 90 min | Imbalanced data, SMOTE, cost-sensitive learning |
| **Lab 2** | Customer Churn | 90 min | Feature engineering, model comparison, batch prediction |
| **Lab 3** | Text Classification | 90 min | TF-IDF, SageMaker Clarify, model explainability |
| **Lab 4** | Sentiment Analysis | 90 min | Multi-class classification, Model Monitor, drift detection |

### Day 2: Advanced MLOps & Deployment

| Lab | Topic | Duration | Key Skills |
|-----|-------|----------|------------|
| **Lab 5** | Feature Store & Registry | 90 min | Feature management, model versioning, lineage tracking |
| **Lab 6** | Advanced Endpoints | 90 min | Serverless inference, async endpoints, multi-model hosting |
| **Lab 7** | SageMaker Pipelines | 90 min | ML automation, CI/CD workflows, pipeline orchestration |
| **Lab 8** | Deployment Strategies | 90 min | Blue/Green, Canary releases, A/B testing |
| **Lab 9** | Generative AI (Bedrock) | 90 min | Claude, Titan, Llama comparison, Guardrails |

## ğŸ—ï¸ Repository Structure

```
aws-ml-training/
â”œâ”€â”€ 01-fraud-detection/          # Lab 1: Fraud detection with SMOTE
â”‚   â”œâ”€â”€ exercises/               # Hands-on exercises with TODOs
â”‚   â”œâ”€â”€ solutions/               # Complete implementations
â”‚   â”œâ”€â”€ data/                    # Sample fraud dataset
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ 02-customer-churn/           # Lab 2: Customer churn prediction
â”œâ”€â”€ 03-text-classification/      # Lab 3: TF-IDF + Clarify
â”œâ”€â”€ 04-sentiment-analysis/       # Lab 4: Multi-class + Model Monitor
â”œâ”€â”€ 05-mlops-packaging/          # Lab 5: Feature Store + Registry
â”œâ”€â”€ 06-mlops-deployment/         # Lab 6: Advanced endpoints
â”œâ”€â”€ 07-mlops-pipelines/          # Lab 7: SageMaker Pipelines
â”œâ”€â”€ 08-deployment-strategies/    # Lab 8: Blue/Green + Canary
â”œâ”€â”€ 09-bedrock-genai/            # Lab 9: Generative AI
â”‚
â”œâ”€â”€ src/ml_toolkit/              # Reusable Python package
â”‚   â”œâ”€â”€ preprocessing.py         # Data preprocessing
â”‚   â”œâ”€â”€ evaluation.py            # Model evaluation
â”‚   â”œâ”€â”€ sagemaker_utils.py       # Deployment helpers
â”‚   â”œâ”€â”€ mlflow_tracking.py       # MLflow integration
â”‚   â”œâ”€â”€ dvc_manager.py           # DVC integration
â”‚   â”œâ”€â”€ debugger.py              # SageMaker Debugger
â”‚   â””â”€â”€ lineage.py               # Model lineage tracking
â”‚
â”œâ”€â”€ tests/                       # Production-quality tests
â”‚   â”œâ”€â”€ unit/                    # Fast unit tests
â”‚   â”œâ”€â”€ integration/             # E2E with SageMaker
â”‚   â””â”€â”€ conftest.py              # Pytest fixtures
â”‚
â”œâ”€â”€ docker/                      # Custom inference containers
â”œâ”€â”€ docs/                        # Additional documentation
â”œâ”€â”€ scripts/                     # Utility scripts
â”œâ”€â”€ pyproject.toml              # Poetry dependencies
â””â”€â”€ Makefile                    # Quick commands
```

## ğŸš€ Getting Started

### Prerequisites

- AWS Account with SageMaker access
- Python 3.9+ installed
- AWS CLI configured (`aws configure`)
- 8GB+ RAM recommended

### Setup in SageMaker Studio

```bash
# 1. Clone repository in SageMaker Studio
cd /home/sagemaker-user/
git clone https://github.com/jwabantequinnovate/aws-ml-training.git
cd aws-ml-training

# 2. Install Poetry
curl -sSL https://install.python-poetry.org | python3 -

# 3. Add Poetry to PATH
export PATH="/home/sagemaker-user/.local/bin:$PATH"
echo 'export PATH="/home/sagemaker-user/.local/bin:$PATH"' >> ~/.bashrc

# 4. Verify Poetry installation
poetry --version

# 5. Install dependencies (make sure you're in the project directory!)
cd /home/sagemaker-user/aws-ml-training
poetry install

# 6. Start Jupyter Lab
poetry run jupyter lab
```

### Running Labs

1. Navigate to any lab folder (e.g., `01-fraud-detection/`)
2. Open the **exercise** notebook in Jupyter Lab
3. Follow the TODO sections
4. Check the **solution** notebook if needed

## ğŸ§ª Testing (Optional - For Advanced Users)

Production-ready code includes comprehensive tests:

```bash
poetry run pytest tests/unit/           # Fast unit tests (no AWS required)
poetry run pytest tests/                # Full test suite
poetry run pytest --cov=src/ml_toolkit  # With coverage report
```

The `src/ml_toolkit/` package demonstrates professional testing practices.

## ğŸ“– Lab Descriptions

### ğŸ”´ Lab 1: Fraud Detection
- Handle imbalanced datasets (1:100 fraud ratio)
- SMOTE for handling class imbalance
- Cost-sensitive learning and threshold optimization
- Model comparison (Logistic Regression, XGBoost, LightGBM)
- Feature importance analysis

### ğŸ“‰ Lab 2: Customer Churn
- Feature engineering from temporal data
- Compare multiple model approaches
- Hyperparameter tuning
- Batch prediction workflows
- Model evaluation and selection

### ğŸ“ Lab 3: Text Classification + Clarify
- TF-IDF text vectorization
- Support ticket classification
- **SageMaker Clarify** for model explainability
- Feature importance analysis
- Regulatory compliance patterns

### ğŸ˜Š Lab 4: Sentiment Analysis + Monitor
- Multi-class sentiment classification
- **SageMaker Model Monitor** setup
- Data drift detection
- Automated monitoring schedules
- Alerting and notifications

### ğŸ“¦ Lab 5: Feature Store & Model Registry
- Centralized feature management
- **SageMaker Feature Store** integration
- Model versioning and lineage
- Artifact tracking
- Team collaboration patterns

### ğŸš€ Lab 6: Advanced Endpoints
- Serverless inference configurations
- Async endpoint patterns
- Multi-model hosting
- **BYOC - Bring Your Own Container** (custom Docker)
- Auto-scaling strategies
- Cost optimization techniques

### ğŸ”„ Lab 7: SageMaker Pipelines
- CI/CD for machine learning
- Automated training workflows
- Model validation gates
- Pipeline orchestration
- Integration with MLOps tools

### ğŸ¯ Lab 8: Deployment Strategies
- Blue/Green deployments
- Canary release patterns
- A/B testing frameworks
- Automated rollbacks
- Traffic shifting strategies

### ğŸ¤– Lab 9: Generative AI with Bedrock
- Compare Claude, Titan, and Llama models
- Prompt engineering techniques
- **Guardrails** for safe AI
- Cost analysis and optimization
- Real-world GenAI applications

## ğŸ› ï¸ Tech Stack

**AWS Services:**
- SageMaker (Training, Endpoints, Pipelines, Feature Store, Model Monitor, Clarify)
- Amazon Bedrock (Claude, Titan, Llama)
- S3, CloudWatch, IAM

**ML Frameworks:**
- Scikit-learn, XGBoost
- Pandas, NumPy

**MLOps Tools:**
- SageMaker Experiments
- SageMaker Debugger
- SageMaker Model Registry
- SageMaker Feature Store

**Development:**
- Python 3.9+
- Poetry (dependency management)
- Pytest (testing)
- Jupyter Lab

## ğŸ¯ Learning Outcomes

After this workshop, you will:

âœ… Train and deploy ML models on AWS SageMaker  
âœ… Handle imbalanced datasets with SMOTE  
âœ… Implement model explainability with Clarify  
âœ… Set up drift detection with Model Monitor  
âœ… Build ML pipelines with SageMaker Pipelines  
âœ… Deploy with Blue/Green and Canary strategies  
âœ… Work with Generative AI using Amazon Bedrock  